
<img width="1112" height="855" alt="image" src="https://github.com/user-attachments/assets/39034a5b-13b7-4b79-912f-f22e99186414" />



Key Components:
Top Section (User Interaction - Real-time Query Flow):

IAM Admin/User â†’ Asks questions about IAM products
Web Interface (React/Streamlit) â†’ Chat UI
API Gateway â†’ Authentication via Cognito/Okta SSO
Lambda RAG Engine â†’ Core orchestration logic:

Converts query to embeddings
Searches vector database
Builds context
Calls Claude Haiku


Bedrock Titan Embeddings â†’ Converts text to vectors
Vector Database â†’ Stores and retrieves similar chunks
Claude 3.5 Haiku â†’ Generates final answer (cost-effective!)

Bottom Section (Ingestion Pipeline - One-time Setup):

S3 Bucket â†’ Stores all IAM PDFs (Okta, SailPoint, SiteMinder, Viper)
Event Trigger â†’ Fires when new PDF uploaded
Lambda PDF Processor â†’ Extracts text and chunks it
Text Chunks â†’ With metadata tags for filtering
Bedrock Titan â†’ Creates embeddings for each chunk
Vector DB â†’ Stores embeddings for future search

Special Features:

Cost Info Box (top right) â†’ Shows pricing estimates
Metadata Tags â†’ Shows how products are filtered
Color Coding â†’ Orange for AWS/Bedrock, Blue for databases, Purple for processing
Legend â†’ Explains arrow types and components

To use in PowerPoint: Right-click â†’ Save or Copy the image!
Would you like me to:

Add more technical details?
Create a simplified version?
Add specific AWS region information?
Include security layers (WAF, VPC)?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
IAM Knowledge Base Chatbot Implementation Guide
Architecture Overview
You're building a Retrieval-Augmented Generation (RAG) chatbot that combines:

Your IAM documentation (Okta, SiteMinder, SailPoint, Viper PDFs)
AWS Bedrock's Claude Haiku (cost-effective LLM)
Vector database for semantic search

Step-by-Step Implementation
Phase 1: Document Ingestion Pipeline
1.1 Set Up S3 Storage
- Create S3 bucket: iam-knowledge-base-docs
- Organize folders: /okta, /sailpoint, /siteminder, /viper
- Upload all PDF documents

1.2 PDF Processing Lambda
This Lambda triggers when PDFs are uploaded to S3:
python# Key functions:
- Extract text from PDFs (use PyPDF2 or textract)
- Split documents into chunks (500-1000 tokens each)
- Maintain metadata: {product: "okta", doc_name: "admin_guide.pdf", page: 5}
- Overlap chunks by 10-20% for context continuity
```

**1.3 Generate Embeddings**
- Use **Amazon Bedrock Titan Embeddings** (cheapest option: ~$0.0001 per 1K tokens)
- Convert each text chunk into a vector (1536 dimensions)
- Embeddings capture semantic meaning for similarity search

**1.4 Store in Vector Database**

**Options:**
- **OpenSearch Serverless** - Best for production, fully managed
- **DynamoDB + FAISS** - Most cost-effective for small/medium datasets
- **Pinecone/Weaviate** - Third-party options

Store: `{chunk_text, embedding_vector, metadata}`
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#### **Phase 2: Query Processing (RAG Engine)**

**2.1 User Query Flow**
```
User: "How do I reset password in Okta?"
    â†“
API Gateway (with Cognito/Okta SSO authentication)
    â†“
Lambda RAG Orchestrator

2.2 RAG Lambda Logic
pythondef handle_query(user_question):
    # Step 1: Convert query to embedding
    query_embedding = bedrock_titan.embed(user_question)
    
    # Step 2: Vector similarity search
    relevant_chunks = vector_db.search(
        query_embedding, 
        top_k=5,  # Get top 5 most relevant chunks
        filter={"product": "okta"}  # Optional: filter by product
    )
    
    # Step 3: Build context
    context = "\n\n".join([chunk.text for chunk in relevant_chunks])
    
    # Step 4: Create prompt for Claude
    prompt = f"""You are an IAM expert assistant. Answer based on this context:
    
    Context: {context}
    
    Question: {user_question}
    
    Answer accurately and cite which product (Okta/SailPoint/SiteMinder/Viper) the info comes from."""
    
    # Step 5: Call Claude Haiku
    response = bedrock_claude_haiku.invoke(
        model_id="anthropic.claude-haiku-3-5-20241022",
        prompt=prompt,
        max_tokens=1000
    )
    
    return response
```
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

2.2 RAG Lambda Logic
pythondef handle_query(user_question):
    # Step 1: Convert query to embedding
    query_embedding = bedrock_titan.embed(user_question)
    
    # Step 2: Vector similarity search
    relevant_chunks = vector_db.search(
        query_embedding, 
        top_k=5,  # Get top 5 most relevant chunks
        filter={"product": "okta"}  # Optional: filter by product
    )
    
    # Step 3: Build context
    context = "\n\n".join([chunk.text for chunk in relevant_chunks])
    
    # Step 4: Create prompt for Claude
    prompt = f"""You are an IAM expert assistant. Answer based on this context:
    
    Context: {context}
    
    Question: {user_question}
    
    Answer accurately and cite which product (Okta/SailPoint/SiteMinder/Viper) the info comes from."""
    
    # Step 5: Call Claude Haiku
    response = bedrock_claude_haiku.invoke(
        model_id="anthropic.claude-haiku-3-5-20241022",
        prompt=prompt,
        max_tokens=1000
    )
    
    return response
```
3.2 Cost Breakdown (Claude Haiku)

Input tokens: $0.80 per million tokens
Output tokens: $4.00 per million tokens
Example: 100K queries/month â‰ˆ $50-100/month

==========================================================

Phase 5: Optimization Tips
5.1 Improve Accuracy

Chunk size: Test 500-1000 tokens
Overlap: 10-20% between chunks
Metadata filtering: Let users select specific products
Prompt engineering: Include examples of good answers

5.2 Reduce Costs

Cache frequent queries (DynamoDB/ElastiCache)
Use Claude Haiku (10x cheaper than Sonnet)
Implement rate limiting
Return fewer chunks (3-5 instead of 10)

Security:

Enable S3 encryption
Use VPC endpoints for Bedrock
Implement API authentication (Cognito/Okta)
Add rate limiting & input validation


Quick Start Steps

Week 1: Set up S3, upload PDFs, create ingestion Lambda
Week 2: Implement embeddings pipeline with Titan, populate vector DB
Week 3: Build RAG Lambda with Claude Haiku integration
Week 4: Create UI, test with real queries, optimize

Testing Your Chatbot
Sample questions to test:

"How do I configure SSO in Okta?"
"What are the password policies in SailPoint?"
"Compare authentication methods in SiteMinder vs Okta"
"Show me troubleshooting steps for Viper login issues"





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

ðŸŽ¯ Complete Flow Components:
Main Request Flow:

START - User types IAM question
Route 53 - DNS resolution with domain details
CloudFront CDN - Edge caching, SSL termination, path routing
Decision Point - Static content OR API call?

Left Path: S3 Static Website â†’ Serve React app
Right Path: Continue to API Gateway



API Processing Flow:

API Gateway - REST endpoint, validation, throttling
Authentication - Cognito/Okta JWT validation
Decision Point - Token valid?

NO: 401 Unauthorized error
YES: Continue to Lambda



RAG Engine (4 Steps):

Lambda RAG Orchestrator - Main processing logic
RAG Step 1 - Create embedding (Bedrock Titan)
RAG Step 2 - Vector search (OpenSearch k-NN)
RAG Step 3 - Build context from top 5 chunks
RAG Step 4 - Call Claude 3.5 Haiku for answer

Response Flow:

Format Response - JSON with answer + citations
Return Path - Back through API Gateway â†’ CloudFront
END - Display answer to user

ðŸ“‹ Key Features:
âœ… Numbered arrows (â‘ -â‘®) showing exact flow sequence
âœ… Color-coded paths:

Black: Main flow
Green: Success/return paths
Red: Error paths
Blue: API requests
Orange: RAG processing

âœ… Detailed component boxes with:

Service names and functions
Technical specifications
API parameters
Latency metrics
Cost information

âœ… Decision diamonds showing:

Static vs API routing
Authentication validation

âœ… Detail boxes (on right side) showing:

Example queries
Configuration parameters
API costs
Response formats

âœ… Performance metrics at bottom showing end-to-end timing
âœ… Legend explaining all arrow types and symbols
This flowchart is presentation-ready and shows every component with clear technical details! Would you like me to adjust anything or create an additional simplified version?RetryClaude can make mistakes. Please double-check responses.


Slide 1: Title Slide

IAM Chatbot Architecture â€“ Using AWS Bedrock Agent

Subtitle: High-level Architecture & Workflow Overview


---

Slide 2: Architecture Components

Key Components Used

User Interface: Web or application used to send queries.

Route 53: Handles domain routing and DNS resolution.

CloudFront: Delivers static UI quickly with caching & CDN.

S3 Static Bucket: Stores and serves the chatbot's frontend interface.

API Gateway: Exposes secure APIs for chatbot interactions.

AWS Lambda: Orchestrates logic and integrates with Bedrock Agent.

AWS Bedrock Agent: Processes natural language queries and performs reasoning.

S3 Document Store: Knowledge base storing PDFs/domains used for retrieval.



---

Slide 3: End-to-End Workflow

How the Chatbot Works

1. The user interacts with the chatbot UI hosted on S3.


2. Route 53 routes the request to CloudFront.


3. CloudFront serves the UI and forwards backend API requests.


4. API Gateway receives the chatbot query.


5. Lambda is triggered to process the request.


6. Lambda invokes the AWS Bedrock Agent for reasoning.


7. The agent retrieves relevant content from S3 knowledge base using RAG.


8. The response flows back: Bedrock Agent â†’ Lambda â†’ API Gateway â†’ User.




---

Slide 4: Why Use AWS Bedrock Agent?

Benefits of Using Bedrock Agent

Supports multi-step reasoning and accurate responses.

Easily integrates with S3 documents for knowledge retrieval.

Supports function calling to trigger custom Lambda actions.

Highly scalable, secure, and managed by AWS.

Reduces development effort with built-in orchestration capabilities.


